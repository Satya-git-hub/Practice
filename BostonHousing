import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsRegressor
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import mean_absolute_error
from sklearn.ensemble import RandomForestRegressor
import sys 
sys.setrecursionlimit(100000)
import impyute.imputation.cs.fast_knn as fast_knn

data = pd.read_csv('BostonHousing.csv')

#data = data.drop(['MEDV'], axis= 1)

#Outlier treatment 
Q1 = data.quantile(0.25)
Q3 = data.quantile(0.75)
IQR = Q3 - Q1
print((data < (Q1 - 1.5*IQR)) | (data > (Q3 + 1.5*IQR)))
data = data[~((data < (Q1 - 1.5*IQR)) | (data > (Q3 + 1.5*IQR))).any(axis=1)]

#missing value treatment

model = fast_knn(data, k=15)
test_dict ={}
for i in range(len(data.columns)):
        test_dict.update({data.columns[i]:model[i]})
data= pd.DataFrame(test_dict)
data.info()

cols = list(data.columns)

plt.hist(data.ZN)

x = data.iloc[:, 0:13].values
y = data.iloc[:, 13].values

xtrain, xtest, ytrain, ytest = train_test_split(x,y, test_size = 0.2, random_state= 13)


scaler = StandardScaler()
xtrain = scaler.fit_transform(xtrain)
xtest = scaler.transform(xtest)
knn_regressor = KNeighborsRegressor()

param = {'n_neighbors': range(1,20)}
cv = GridSearchCV(knn_regressor, param, cv=5, n_jobs=-1)
cv.fit(xtrain, ytrain)
cv.best_params_

knn_regressor = KNeighborsRegressor(n_neighbors=5, n_jobs=-1)
knn_regressor.fit(xtrain, ytrain)
ypred = knn_regressor.predict(xtest)
knn_error = mean_absolute_error(ytest, ypred)
#Out[29]: 2.2658181818181817

rf_regressor = RandomForestRegressor()

param = {'n_estimators': range(1,20), 
         'criterion':['mse', 'mae'], 
         'max_depth':range(1,50)}
rf_cv =GridSearchCV(rf_regressor, param, cv=5)
rf_cv.fit(xtrain, ytrain)
rf_cv.best_params_

rf_regressor = RandomForestRegressor(n_estimators= 19, criterion='mse' , max_depth= 19, random_state=13)
rf_regressor.fit(xtrain, ytrain)
ypred = rf_regressor.predict(xtest)

rf_error = mean_absolute_error(ytest, ypred)
#Out[34]: 2.0546411483253597






